#NMDS
# Non-metric multidimensional scaling (NMDS) is one tool commonly used to 
# examine community composition

# Let's lay some conceptual groundwork
# Consider a single axis of abundance representing a single species:
plot(0:10,0:10,type="n",axes=F,xlab="Abundance of Species 1",ylab="")
axis(1)
# We can plot each community on that axis depending on the abundance of 
# species 1 within it
points(5,0); text(5.5,0.5,labels="community A")
points(3,0); text(3.2,0.5,labels="community B")
points(0,0); text(0.8,0.5,labels="community C")

# Now consider a second axis of abundance representing a different 
# species
# Communities can be plotted along both axes depending on the abundance of
# species within it
plot(0:10,0:10,type="n",xlab="Abundance of Species 1",
     ylab="Abundance of Species 2")
points(5,5); text(5,4.5,labels="community A")
points(3,3); text(3,3.5,labels="community B")
points(0,5); text(0.8,5.5,labels="community C")

# Now consider a THIRD axis of abundance representing yet another species
# (For this we're going to need to load another package)
# install.packages("scatterplot3d")
library(scatterplot3d)
d=scatterplot3d(0:10,0:10,0:10,type="n",xlab="Abundance of Species 1",
                ylab="Abundance of Species 2",
                zlab="Abundance of Species 3"); d
d$points3d(5,5,0); text(d$xyz.convert(5,5,0.5),labels="community A")
d$points3d(3,3,3); text(d$xyz.convert(3,3,3.5),labels="community B")
d$points3d(0,5,5); text(d$xyz.convert(0,5,5.5),labels="community C")

# Now consider as many axes as there are species S (obviously we cannot 
# visualize this beyond 3 dimensions)
# Hopefully your head didn't explode

# The goal of NMDS is to represent the original position of communities in
# multidimensional space as accurately as possible using a reduced number 
# of dimensions that can be easily plotted and visualized 

# NMDS does not use the absolute abundances of species in communities, but
# rather their RANK ORDER!
# The use of ranks omits some of the issues associated with using absolute
# distance (e.g., sensitivity to transformation), and as a result is much 
# more flexible technique that accepts a variety of types of data
# (It is also where the "non-metric" part of the name comes from)

# The NMDS procedure is iterative and takes place over several steps:
# (1) Define the original positions of communities in multidimensional 
# space 
# (2) Specify the number m of reduced dimensions (typically 2)
# (3) Construct an initial configuration of the samples in 2-dimensions
# (4) Regress distances in this initial configuration against the observed 
# (measured) distances
# (5) Determine the stress (disagreement between 2-D configuration and 
# predicted values from regression)
# If the 2-D configuration perfectly preserves the original rank 
# orders, then a plot ofone against the other must be monotonically 
# increasing. The extent to which the points on the 2-D configuration
# differ from this monotonically increasing line determines the
# degree of stress (see Shepard plot)
# (6) If stress is high, reposition the points in m dimensions in the 
#direction of decreasing stress, and repeat until stress is below 
#some threshold 

# Generally, stress < 0.05 provides an excellent represention in reduced 
# dimensions, < 0.1 is great, < 0.2 is good, and stress > 0.3 provides a 
# poor representation

# NOTE: The final configuration may differ depending on the initial 
# configuration (which is often random) and the number of iterations, so
# it is advisable to run the NMDS multiple times and compare the 
# interpretation from the lowest stress solutions

# To begin, NMDS requires a distance matrix, or a matrix of 
# dissimilarities
# Raw Euclidean distances are not ideal for this purpose: they are 
# sensitive to totalabundances, so may treat sites with a similar number
# of species as more similar, even though the identities of the species
# are different
# They are also sensitive to species absences, so may treat sites with
# the same number of absent species as more similar

# Consequently, ecologists use the Bray-Curtis dissimilarity calculation, 
# which has many ideal properties:
# It is invariant to changes in units
# It is unaffected by additions/removals of species that are not 
# present in two communities
# It is unaffected by the addition of a new community
# It can recognize differences in total abudnances when relative 
# abundances are the same

# To run the NMDS, we will use the function `metaMDS` from the vegan 
# package
#install.packages("vegan")
library(vegan)
# `metaMDS` requires a community-by-species matrix
# Let's create that matrix with some randomly sampled data
set.seed(2)
community_matrix=matrix(sample(1:100,300,replace=T),nrow=10,
                        dimnames=list(paste("community",1:10,sep=""),
                                      paste("sp",1:30,sep="")))

# The function `metaMDS` will take care of most of the distance 
# calculations, iterative fitting, etc. We need simply to supply:
example_NMDS=metaMDS(community_matrix, # Our community-by-species matrix
                     k=2) # The number of reduced dimensions
# You should see each iteration of the NMDS until a solution is reached
# (i.e., stress was minimized after some number of reconfigurations of 
# the points in 2 dimensions). You can increase the number of default 
# iterations using the argument "trymax=##"
example_NMDS=metaMDS(community_matrix,k=2,trymax=100)

# And we can look at the NMDS object
example_NMDS # metaMDS has automatically applied a square root 
# transformation and calculated the Bray-Curtis distances for our 
# community-by-site matrix
# Let's examine a Shepard plot, which shows scatter around the regression
# between the interpoint distances in the final configuration (distances 
# between each pair of communities) against their original dissimilarities
stressplot(example_NMDS)
# Large scatter around the line suggests that original dissimilarities are
# not well preserved in the reduced number of dimensions

#Now we can plot the NMDS
plot(example_NMDS)
# It shows us both the communities ("sites", open circles) and species 
# (red crosses), but we  don't know which are which!

# We can use the functions `ordiplot` and `orditorp` to add text to the 
# plot in place of points
ordiplot(example_NMDS,type="n")
orditorp(example_NMDS,display="species",col="red",air=0.01)
orditorp(example_NMDS,display="sites",cex=1.25,air=0.01)

# There are some additional functions that might of interest
# Let's suppose that communities 1-5 had some treatment applied, and 
# communities 6-10 a different treatment
# We can draw convex hulls connecting the vertices of the points made by
# these communities on the plot
# First, let's create a vector of treatment values:
treat=c(rep("Treatment1",5),rep("Treatment2",5))
ordiplot(example_NMDS,type="n")
ordihull(example_NMDS,groups=treat,draw="polygon",col="grey90",
         label=FALSE)
orditorp(example_NMDS,display="species",col="red",air=0.01)
orditorp(example_NMDS,display="sites",col=c(rep("green",5),rep("blue",5)),
         air=0.01,cex=1.25)
# I find this an intuitive way to understand how communities and species 
# cluster based on treatments
# One can also plot ellipses and "spider graphs" using the functions 
# `ordiellipse` and `orderspider` which emphasize the centroid of the 
# communities in each treatment

# Another alternative is to plot a minimum spanning tree (from the 
# function `hclust`), which clusters communities based on their original 
# dissimilarities and projects the dendrogram onto the 2-D plot
ordiplot(example_NMDS,type="n")
orditorp(example_NMDS,display="species",col="red",air=0.01)
orditorp(example_NMDS,display="sites",col=c(rep("green",5),rep("blue",5)),
         air=0.01,cex=1.25)
ordicluster(example_NMDS,hclust(vegdist(community_matrix,"bray"))) 
# Note that clustering is based on Bray-Curtis distances
# This is one method suggested to check the 2-D plot for accuracy

# You could also plot the convex hulls, ellipses, spider plots, etc. colored based on the treatments
# First, create a vector of color values corresponding of the same length as the vector of treatment values
colors=c(rep("red",5),rep("blue",5))
ordiplot(example_NMDS,type="n")
#Plot convex hulls with colors baesd on treatment
for(i in unique(treat)) {
  ordihull(example_NMDS$point[grep(i,treat),],draw="polygon",groups=treat[treat==i],col=colors[grep(i,treat)],label=F) } 
orditorp(example_NMDS,display="species",col="red",air=0.01)
orditorp(example_NMDS,display="sites",col=c(rep("green",5),rep("blue",5)),
         air=0.01,cex=1.25)

# If the treatment is a continuous variable, consider mapping contour 
# lines onto the plot
# For this example, consider the treatments were applied along an 
# elevational gradient
# We can define random elevations for previous example
elevation=runif(10,0.5,1.5)
# And use the function ordisurf to plot contour lines
ordisurf(example_NMDS,elevation,main="",col="forestgreen")
# Finally, we want to display species on plot
orditorp(example_NMDS,display="species",col="grey30",air=0.1,cex=1)


##############################################################################################################

###Non-parametric tests
##Kruskal-Wallis (equivalent to an ANOVA)
#plotting the data

A<-c(27,14,8,18,7)
B<-c(48,18,32,51,22)
C<-c(11,0,3,15,8)
D<-c(44,72,81,55,39)

#take a look at the data
summary(A) 
summary(B)
summary(C)
summary(D)

#Taking a better look at the differences between samples
boxplot(A,B,C,D, names=c("A","B","C","D"), ylab="No. orquÃ­deas",
col=3)

#Puts the data on a vertical format
orq.dados<-data.frame(Campo<-gl(4,5), Orquideas<-c(A,B,C,D))

#Check the data
orq.dados

#Runs the Kruskal Wallis test
kruskal.test(Orquideas~Campo, orq.dados)

##########################################################

#Mann-whitney Wilcoxon test
A<-c(8,12,15,21,25,44,44,60)
B<-c(2,4,5,9,12,17,19)
boxplot(A,B, names=c("A","B")) #used to verify if the statistics of the network are right
wilcox.test(A,B) #runs the test

#Mann-Whitney Wilcoxon paired test
ago<-c(10.3,11.4,10.9,12.0,10.0,11.9,12.2,12.3,11.7,12.0)
set<-c(12.2,12.1,13.1,11.9,12.0,12.9,11.4,12.1,13.5,12.3)
boxplot(ago,set,names=c("Agosto","Setembro"))
wilcox.test(ago,set, paired=TRUE)



##############################################################################

correnteza<-c(rep("forte",7),rep("fraco",7),rep("moderado",7))
nadadeira<-c(30,70,50,60,70,50,40,30,50,40,50,20,20,30,40,50,40,60,60,50,40)
peixe<-data.frame(correnteza,nadadeira)
rm(correnteza)
rm(nadadeira)
str(peixe)
attach(peixe)
head(peixe)

#VisualizaÃ§Ã£o de Dados
boxplot(nadadeira~correnteza, col="red",ylab="Nadadeira")

#To rotate boxplot labels, add las=2 to the general formula

#Testa premissa de normalidade
shapiro.test(nadadeira[correnteza=="forte"])
shapiro.test(nadadeira[correnteza=="fraco"])
shapiro.test(nadadeira[correnteza=="moderado"])

#Test specific columns for normality inside spreadsheet (P.mesoamericanus_normal in the below case)
shapiro.test(motut$P.mesoamericanus_normal)


#Testa premissa de homocedasticidade
bartlett.test(nadadeira~correnteza)

#Calcula mÃ©dia
(x.forte<-mean(nadadeira[correnteza=="forte"]))
(x.fraco<-mean(nadadeira[correnteza=="fraco"]))
(x.moderado<-mean(nadadeira[correnteza=="moderado"]))
(x.total<-mean(nadadeira))

#Calcula as Somas de Quadrados (SS)
(ss.total<-sum((nadadeira-x.total)^2))
(ss.dentro.forte<-sum((nadadeira[correnteza=="forte"]-x.forte)^2))
(ss.dentro.fraco<-sum((nadadeira[correnteza=="fraco"]-x.fraco)^2))
(ss.dentro.moderado<-sum((nadadeira[correnteza=="moderado"]-x.moderado)^2))
(ss.dentro<-ss.dentro.forte+ss.dentro.fraco+ss.dentro.moderado)
(ss.entre.forte<-7*(x.forte-x.total)^2)
(ss.entre.fraco<-7*(x.fraco-x.total)^2)
(ss.entre.moderado<-7*(x.moderado-x.total)^2)
(ss.entre<-ss.entre.forte+ss.entre.fraco+ss.entre.moderado)

#Calcula variÃ¢ncia (MS)
(ms.entre<-ss.entre/(3-1))
(ms.dentro<-ss.dentro/((7-1)*3))

#Teste F
(f<-ms.entre/ms.dentro)
curve(df(x,2,18),0,5)
abline(v=f,col="red",lwd=2)
1-(pf(f,2,18)) #valor de p
qf(0.95,2,18) #valor crÃ­tico para alfa=0,05

#Faz ANOVA
a<-aov(nadadeira~correnteza)
summary(a)

#ProporÃ§Ã£o da variaÃ§Ã£o total explicada por correnteza (rÂ²)
ss.entre/ss.total

#Teste de comparaÃ§Ã£o mÃºltipla
TukeyHSD(a)

#ANOVA nÃ£o-paramÃ©trica
kruskal.test(nadadeira~correnteza)

r.nadadeira<-rank(nadadeira)
r.nadadeira
nadadeira
summary(aov(r.nadadeira~correnteza))
h<-522.9/var(r.nadadeira)
h

14/01/2013
#Define o diretÃ³rio de trabalho
setwd("/Users/grcolli_on_bachia/Desktop")
getwd

#Carrega os dados
beija.flor<-read.table("aula6a.dat",h=T)
head(beija.flor)
attach(beija.flor)
class(beija.flor)

#Visualiza dados
table(bloco,acucar) (mostra quantas combinaÃ§Ãµes existem para os blocos e os aÃ§Ãºcares)
table(bloco) (mostra quantas observaÃ§Ãµes existem oara cada bloco)
table(acucar) (mostra quantas observaÃ§Ãµes existem para cada variÃ¡vel aÃ§Ãºcar)
par(mfro=c(1,2))
plot(frequencia~bloco+acucar,las=1,col="cyan") (faz um grÃ¡fico pra blocos mais um grÃ¡fico para aÃ§Ãºcares)
par(mfrow=c(1,1))

#Faz ANOVA de Blocos AleatÃ³rios
anova.beija.flor<-aov(frequencia-bloco+acucar) (como eu nÃ£o estou interessado na interaÃ§Ã£o entre o bloco e aÃ§Ãºcar, colocasse o sinal de adiÃ§Ã£o(+). Caso houvesse interesse em verificar a interaÃ§Ã£o, deveria ser colocado o sinal de vezes (*)) 
                                               (se ele estivesse interessado na interaÃ§Ã£o, ele teria colocado Vezes no lugar de sinal de adiÃ§Ã£o)
#Calcula mÃ©dias
model.tables(anova.beija.flor,"means",se=T) (ele Ã© interessante porque ele dÃ¡ a mÃ©dia total por blocos e por tratamento, alÃ©m do erro-padrÃ£o para as diferenÃ§as de mÃ©dia)
model.tables(anova.beija.flor,"effects",se=T)
plot.design(frequencia~bloco+acucar)

#Testes de comparaÃ§Ã£o mÃºltiplo
TukeyHSD(anova.beija.flor)
parwise.t.test(frequencia,acucar,p.adj="bonf")
parwise.t.test(frequencia,acucar,p.adj="holm")

#Testa premissas (o teste de premissas muitas vezes Ã© feito por meio da anÃ¡lise dos resÃ­duos)
par(mfrow=c(2,2))
plot(anova.beija.flor)
par(mfrow=c(1,1))
pnorm(-0.0005)
qnorm(-0.0005)
qnorm(0.999)
qnorm(0.9995)
sqrt(qnorm(0.995))
sqrt(qnorm(0.999))
shapiro.test(porcentagem[RB])
shapiro.test(porcentagem[RB=="RB"])
shapiro.test(frequencia[acucar=="sacarose"])
shapiro.test(anova.beija.flor$residuals)
print.deafult(anova.beija.flor) (imprime tudo o que existe dentro do objeto entre parÃªnteses)
bartlett.test(RB~porcentagem)
fligner.test(frequencia~acucar) (Outro teste possÃ­vel para homocedasticidade)
class(anova.beija.flor)
summary(aov(frequencia~bloco+acucar))
summary(aov(frequencia~acucar))

## ANOVA fatorial
# ***************

#Carrega os dados
peixes<-read.table("aula6b.dat",h=T)
head(peixes)
attach(peixes)

#Visualiza os dados
table(isca,trecho)
table(isca)
table(trecho)
par(mfrow=c(1,2))
plot(capturas~isca+trecho,las=1,col="cyan")
par(mfrow=c(1,1))
interaction.plot(isca,trecho,capturas)
interaction.plot(trecho,isca,capturas)

#Faz ANOVA fatorial
anova.peixes<-aov(capturas~isca+trecho)
summary(anova.peixes)

#Calcula mÃ©dias
tapply(capturas,isca,mean)
model.tables(anova.peixes,"means")

#Teste de ComparaÃ§Ã£o MÃºltipla
TukeyHSD(anova.peixes)
parwise.t.test(capturas,isca,p.adj="holm")

#Testa premissas (o teste de premissas muitas vezes Ã© feito por meio da anÃ¡lise dos resÃ­duos)
par(mfrow=c(2,2))
plot(anova.peixes)
par(mfrow=c(1,1))
shapiro.test(anova.peixes$residuals)
bartlett.test(capturas~isca)
bartlett.test(capturas~trecho)
bartlett.test(capturas~isca*trecho)
fligner.test(capturas~isca)
fligner.test(capturas~trecho)
fligner.test(capturas~trecho*isca)

modelo1<-anova.peixes
modelo2<-aov(captura~isca)
anova(modelo1,modelo2)
summary(aov(rank(capturas)~isca*trecho))
summary(aov(capturas)~isca*trecho))

15/01/2013
#Entra os dados
especie<-c(rep("G.amarali",8),rep("G.darwini",8),rep("G.geckoides",8))
especie
individuo<-c("a","a","b","b","c","c","d","d","e","e","f","f","g","g","h","h","i","i","j","j","k","k","l","l")
ovo<-rep(c("um","dois"),12)
massa<-c(585,595,778,809,840,836,701,683,698,698,560,545,507,493,638,658,566,575,778,792,699,692,621,645)
lagartos<-data.frame(especie,individuo,ovo,massa)
rm(especie,individuo,ovo,massa)
head(lagartos)
attach(lagartos)
length(massa)

#Faz ANOVA normal
summary(aov(massa~especie))

#Faz ANOVA HierÃ¡rquica
anova.lagartos<-aov(massa~especie+Error(individuo/especie)) 
(quando se coloca error, vai se dizer qual Ã© a variaÃ§Ã£o individual)
summary(anova.lagartos)
curve(df(x,2,21),col="red",lwd=3,xlim=c(0,4),ylim=c(0,1))
curve(df(x,2,9),col="blue",lwd=3,xlim=c(0,4),ylim=c(0,1),add=T)
qf(0.95,2,21)
qf(0.95,2,9)

#Calcula mÃ©dias
medias.ovos<-aggregate(massa,list(Individuo=individuo),mean)
medias.ovos
m<-tapply(massa,individuo,mean)
m
class(m)
class(medias.ovos)
sp<-c(rep("G.amarali",4),rep("G.darwini",4),rep("G.geckoides",4)

anova.medias<-aov(massa~especie+Error(individuo/especie)) 


#Faz ANOVA com mÃ©dias
summary(aov(medias.ovos$x-sp))

##ANOVA de Medidas Repetidas
#***************************

berne<-c(1,1,3,5,2,3,4,3,5,4,6,8,6,7,5)
mes<-c(rep("m1",5),rep("m2",5),rep("m3",5))
sujeito<-rep(c("t1","t2","t3","t4","t5"),3)
tatu<-data.frame(sujeito,mes,berne)
rm(sujeito,mes,berne)
attach(tatu)
head(tatu)
tatu

#ANOVA normal
summary(aov(berne~mes))

#ANOVA de Medidas Repetidas
anova.tatu<-aov(berne~mes+Error(sujeito/mes)) (caso se estivesse interessado na interaÃ§Ã£o, seria mes*tratamento em todos os casos. Quando se coloca mes*tratamento, ele calcula o valor do tratamento, o valor do mes e o valor da interaÃ§Ã£o entre os dois)) anova.tatu<-aov(berne~mes*tratamento+Error(sujeito/mes*tratamento))
summary(anova.tatu)

#ANOVA de Medidas Repetidas Fatorial
anova.tatu<-aov(berne~mes*tratamento+Error(sujeito/mes*tratamento))

#Teste de Premissas
par(mfrow=c(2,2))
plot(anova.tatu)
par(mfrow=c(1,1))
anova.tatu$residuals

#Interaction plot
interaction.plot(mes,sujeito,berne)


16/01/2013

***** CorrelaÃ§Ã£o linear
library(MASS)
data(crabs)
head(crabs)
tail(crabs)
attach(crabs)

#Covariancia
cov(CL,CL)
var(CL) #a covariÃ¢ncia de uma variavel consigo mesma e a sua variancia
cov(CL,FL) #a covariÃ¢ncia de duas variaveis independentes Ã© zero.
cov(FL,CL)
sum(((CL-mean(CL))*FL-mean(FL)))/(length(FL)-1))
constante<-rep(50,200)
constante
cov(CL,constante)
cov(crabs[,-c(1:3)])
cov(crabs[,4:8]) #como as covariÃ¢ncias dependem da escala, elas devem ser padronizadas de acordo com o desvio-padrÃ£o para que o problema da escala seja resolvido e isso Ã© feito
var(FL)                   
cor(CL,CW) #a partir desse valor, ainda tem que ser testada a significÃ¢ncia
cov(CL,CW)
plot(CL,CW,type="p",pch=1,cex=2,col="red") #pch= plot character #dica: mexer em nomes do grÃ¡fico em outro programa (corel)
pairs(crabs[,4:8],col="red") #faz a correlaÃ§Ã£o entre variÃ¡veis par a par
cor(crabs[,4:8])
cor.test(CL,CW)
shapiro.test(CW)
shapiro.test(CL)

#CorrelaÃ§Ã£o de Spearman(nao-parametrica)
cor.test(porcentagem,RB,method="spearman")
cor.test(rank(CW),rank(CL)) #estes dois comandos sÃ£o equivalentes

#Regressao
modelo<-lm(CW~CL)
modelo
abline(modelo,col="blue")
abline(v=mean(CL),lty=2)
abline(h=mean(CW),lty=2)
anova(modelo)
sum((CW-mean(CW))^2)
SS.total<-sum((CW-mean(CW))^2)
SS.residuals<-sum((CW-predict(modelo))^2)
SS.modelo<-sum((predict(modelo)~mean(CW))^2)
SS.total
SS.residuals
SS.modelo
SS.modelo/SS.total #coeficiente de determinaÃ§Ã£o
cor(CL,CW)^2
curve(df(x,1,198))

par(mfrow=c(2,2))
plot(mfrow=c(2,2))
plot(modelo)

shapiro.test(residuals(modelo))
plot(rstandard(modelo)) #grÃ¡fico dos resÃ­duos padronizados
plot(rstudent(modelo))
influence.measures(modelo) # o melhor indicador Ã© a distÃ¢ncia de cook e o asterisco representa a influÃªncia
plot(cooks.distance(modelo,type="h")) #faz um grÃ¡fico somente sobre a distÃ¢ncia de cook. SÃ³ Ã© preocupante se a distÃ¢ncia de Cook for maior do que 2.
boxplot(rstandard(modelo))
qnorm(0,99)

Aula 17/01/2013

#Carrega os dados
library(MASS)
data(crabs)
head(crabs)

#Faz regressao multipla
reg<-lm(CW~FL+RW+BD+CL, crabs) #a ordem das variÃ¡veis nÃ£o Ã© importante. Se houver interesse nas interaÃ§Ãµes, basta colocar um asterisco entre as variÃ¡veis da fÃ³rmula)
summary(reg)
anova(reg) #Usa-se o comando anova quando jÃ¡ se tem os valores. Caso 
attach(crabs)
var(CW)*199

#Calcula coeficientes padronizados
reg.std<-lm(CW~scale(FL)+scale(RW)+scale(CL)+scale(BD))
summary(reg.std)

#Faz seleÃ§Ã£o automÃ¡tica de modelos
summary(step(reg))
stepAIC(reg,direction="backward",trace=2)

#Faz seleÃ§Ã£o manual de modelos
modelo.nulo<-lm(CW~1,crabs)
modelo.completo<-lm(CW~FL+RW+CL+BD)

#Tenta remover variÃ¡veis do modelo completo
drop1(modelo.completo,test=c("F"),trace=T) #o p mostrarÃ¡ se a retirada do modelo Ã© significativo ou nÃ£o
?drop1

#Tenta acrescentar variÃ¡veis do modelo nulo
add1(modelo.nulo,scope=formula(modelo.completo),test=c("F")) #o scope servirÃ¡ para dizer de onde ele retirarÃ¡ os dados das variÃ¡veis para acrescentar ao modelo. Nesse caso, ele retirarÃ¡ as variÃ¡veis da fÃ³rmula do modelo.completo que jÃ¡ foi colocado antes. 

#Acrescenta CL ao modelo
modelo.nulo<-update(modelo.nulo,.~.+CL) # .~. significa manter tudo o que estava antes

#Tenta remover variaveis do modelo
drop1(modelo.nulo,test=c("F"),trace=T)

#Tenta acrescentar variÃ¡veis do modelo nulo
add1(modelo.nulo,scope=formula(modelo.completo),test=c("F")) #o scope servirÃ¡ para dizer de onde ele retirarÃ¡ os dados das variÃ¡veis para acrescentar ao modelo. Nesse caso, ele retirarÃ¡ as variÃ¡veis da fÃ³rmula do modelo.completo que jÃ¡ foi colocado antes. 

#Acrescenta CL ao modelo
modelo.nulo<-update(modelo.nulo,.~.+RW) # .~. significa manter tudo o que estava antes

#Tenta remover variaveis do modelo
drop1(modelo.nulo,test=c("F"))

#Analise de modelo medio
install.packages("MuMIn", dependence=T)
library(MuMIn)
dd.reg<-dredge(reg)
dd.reg

modelos.selecionados<-get.models(dd.reg,delta<60) #60 Ã© o valor de delta observado na tabela para o qual parece existir uma piora significativa na qualidade de explicaÃ§Ã£o do modelo
summary(modelos.selecionados)
summary(model.avg(modelos.selecionados))
summary(reg)

#Testa premissas
par(mfrow=c(2,2))
plot(reg)
par(mfrow=c(1,1))
pairs(crabs[,4:8])
cor(crabs[,4:8])

#Analise de covariancia
attach(crabs)
plot(CL,CW,pch=1,col=c("blue","orange")[as.numeric(sp)],cex=2)
cor.test(CW,CL)
summary(lm(CW~CL*sp)) #testa premissa de ausÃªncia de interaÃ§Ã£o
summary(lm(CW~CL+sp)) #faz ANCOVA (invalido nesse caso devido Ã¡ interaÃ§Ã£o, mas o comando da ancova Ã© esse)


#### AnÃ¡lise de Componentes Principais
#**********************************

#Carrega os dados
library(MASS)
data(crabs)
attach(crabs)
head(crabs)

#VisualizaÃ§Ã£o de Dados Multivariados
pairs(crabs[,4:8],pch=19,col="red")

#Matrizes de correlaÃ§Ã£o e covariancia
cor(crabs[,4:8])
cor(crabs[,c(4,5,8)) #correlaciona variÃ¡veis especÃ­ficas

#Matrizes de correlaÃ§Ã£o e covariÃ¢ncia
cov.crabs<-cor(crabs[,4:8])
round(cov.crabs,2)
sum(diag(cov.crabs)) #a diagonal principal tem as variÃ¢ncias e os outros dados sÃ£o as covariÃ¢ncias.
sscp.crabs<-cov.crabs*199
round(sscp.crabs,2)
sum(sscp.crabs)
sum(diag(sscp.crabs))
round(cor(crabs[,4:8]),2) #numa matriz de 5 x 5, existem 10 correlaÃ§Ãµes importantes a serem verificadas.
diag(sscp.crabs)

#Faz PCA
pca.crabs<-prcomp(crabs[,4:8])
pca.crabs
summary(pca.crabs) #autovaloes
round(pca.crabs$rotation,2) #autovetores #o coeficiente nÃ£o significa 
diag(cov.crabs)
plot(pca.crabs)
biplot(pca.crabs) #os scores estÃ£o padronizados
biplot(pca.crabs,pch=1,col=as.number)
abline(h=0,lwd=1,lty=2,col="blue")
pca.crabs$rotation[,1]
pca.crabs$rotation[1]
pca.crabs$x       #os scores nÃ£o estÃ£o padronizados aqui

#Faz PCA com matriz de correlaÃ§Ã£o
pca.crabs<-prcomp(crabs[,4:8], scale=T)  #resultados independentes da escala
pca.crabs
summary(pca.crabs) #autovaloes
round(pca.crabs$rotation,2) #autovetores #o coeficiente nÃ£o significa 
diag(cov.crabs)
plot(pca.crabs)
biplot(pca.crabs) #os scores estÃ£o padronizados
biplot(pca.crabs,pch=1,col=as.number)
abline(h=0,lwd=1,lty=2,col="blue")
pca.crabs$rotation[,1]
pca.crabs$rotation[1]
pca.crabs$x       #os scores nÃ£o estÃ£o padronizados aqui
cor(pca.crabs$x)

#Calcula os scores
autovetores<-pca.crabs$rotation
autovetores
class(autovetores)
dados<-as.matrix(crabs[,4:8])
scores.pca<-dados%*%autovetores #o sinal de % Ã© devido Ã  multiplicaÃ§Ã£o de matrizes
var(scores.pca)  #os scores representam a variaÃ§Ã£o total dos dados, mas a variaÃ§Ã£o estÃ¡ redistribuÃ­da
sum(diag(var(scores.pca))
cor(scores.pca)
plot(scores.pca[,1],scores.pca[,2])
plot(scale(scores.pca[,1]),scale(scores.pca[,2]))


21/01/2013
##AnÃ¡lise de CorrespondÃªncia
#-----------

install.packages("vegan",dependencies=T)
library(vegan)
data(dune)
head(dune)

#PCA
plot(prcomp(dune))
biplot(prcomp(dune))
cov(dune)
cor(dune)

#Calcula qui-quadrado
soma.linhas<-apply(dune,1,sum) #quando se coloca 1 no comando apply, o R soma linhas
soma.linhas #observÃ§Ãµes (indivÃ­duos) por sÃ­tios
plot(sort(soma.linhas,decreasing=T),type="h",lwd=10,col="blue")

soma.colunas<-apply(dune,2,sum) #quando se coloca 2 no comando apply, O R soma linhas
soma.colunas #observÃ§Ãµes (indivÃ­duos) por espÃ©cies
plot(sort(soma.colunas,decreasing=T),type="h",lwd=10,col="red")

soma.total<-sum(dune)
soma.total

f.esperado<-(soma.linhas%o%soma.colunas)/soma.total
f.esperado

qui.quadrado<-sum((dune-f.esperado)^2/f.esperado)
qui.quadrado

#Ca com vegan
dune.ca<-cca(dune)
dune.ca
summary(dune.ca)

qui.quadrado/soma.total #inertia

plot(dune.ca)
biplot(prcomp(dune),pc.biplot=T)
plot(dune.ca,scaling=1) #o scaling provoca mais uma mudanÃ§a nas escalas dos dados, mas nÃ£o modifica o reusltado da anÃ¡lise

library(MASS)
ca.dune<-corresp(dune)
ca.dune
biplot(ca.dune,nf=2)

install.packages("ca",dependencies=T)
1-pchisq(qui.quadrado,(19*20))
chisq.test(dune)

22/01/2013
## AnÃ¡lise de agrupamento (vamos tentar agrupar os caranguejos apenas por meio de suas medidas corporais)

#carrega pacotes
library(vegan)
library(MASS)

#Carrega os dados
data(crabs)
head(crabs)
obs<-sample(1:200,20) #seleciona 20 nÃºmeros ao acaso da amostra de 200 repetiÃ§Ãµes sem reposiÃ§Ã£o
obs
sort(obs) #ordena os valores
amostras<-c(12,21,23,24,28,41,47,54,70,76,91,92,93,101,112,115,131,146,177,197)
sum(amostras)
crabs.20<-crabs[amostras,]
crabs.20

#Visualiza 20 observaÃ§Ãµes
pc.crabs.20<-prcomp(crabs.20[,4:8],scale=T)
pc.crabs.20
par(mfrow=c(1,2))
plot(pc.crabs.20$x[,1],pc.crabs.20$x[,2],pch=c("F","M")[as.numeric(crabs.20$sex)])
plot(pc.crabs.20$x[,1],pc.crabs.20$x[,2],col=c("blue","orange")[as.numeric(crabs.20$sp)])
par(mfrow=c(1,1))

#Calcula a matriz de distÃ¢ncias
crabs.dist<-vegdist(crabs.20[,4:8],method="euclidean") #faz uma matriz de distÃ¢ncias utilizando a distÃ¢ncia euclidiana
round(crabs.dist,1)
crabs.dist
?vegdist
row.names(crabs) #lista o nÃºmero das linhas

#Esperimenta diferentes aÃ§goritmos
crabs.single<-hclust(crabs.dist,method="single") #hclust manda fazer um agrupamento hierÃ¡rquico e manda fazer um dendrograma  #o mÃ©todo single Ã© o mÃ©todo de agrupamento pelo vizinho mais prÃ³ximo. Ele pergunta qual a menor distÃ¢ncia entre dois caranguejos.
plot(crabs.single,pch)

crabs.complete<-hclust(crabs.dist,method="complete") #o complete manda fazer a menor distÃ¢ncia ao vizinho mais distante
plot(crabs.complete)

crabs.UPGMA<-hclust(crabs.dist,method="average") #o average manda fazer a menor distÃ¢ncia mÃ©dia
plot(crabs.UPGMA)

crabs.UPGMC<-hclust(crabs.dist,method="centroid") #faz a menor distÃ¢ncia entre as distÃ¢ncias dos centrÃ³ides # mostra um encadeamento entre os grupos
plot(crabs.UPGMC)

crabs.ward<-hclust(crabs.dist,method="ward") #minimiza a variÃ¢ncia entre as distÃ¢ncias
plot(crabs.ward)

#CorrelaÃ§Ã£o cofrenÃ©tica
crabs.single.cof<-cophenetic(crabs.single)
cor(crabs.dist,crabs.single.cof)

crabs.complete.cof<-cophenetic(crabs.complete)
cor(crabs.dist,crabs.complete.cof)

crabs.UPGMA.cof<-cophenetic(crabs.UPGMA)
cor(crabs.dist,crabs.UPGMA.cof)

crabs.UPGMC.cof<-cophenetic(crabs.UPGMC)
cor(crabs.dist,crabs.UPGMC.cof)

crabs.ward.cof<-cophenetic(crabs.ward)
cor(crabs.dist,crabs.ward.cof)

#DistÃ¢ncia de Gower (somas de quadrados) -> Ã© uma medida dos ajustes. Seria a soma dos quadrados dos resÃ­duos. O melhor mÃ©todo seria aquele que tem o meor valor, pois representa que existe uma menor diferenÃ§a entre o observado e o esperado.
gower.dist.simples<-sum((crabs.single.cof-crabs.dist)^2)
gower.dist.complete<-sum((crabs.complete.cof-crabs.dist)^2)
gower.dist.UPGMA<-sum((crabs.UPGMA.cof-crabs.dist)^2)
gower.dist.UPGMC<-sum((crabs.UPGMC.cof-crabs.dist)^2)
gower.dist.ward<-sum((crabs.ward.cof-crabs.dist)^2)

#GrÃ¡fico da largura da silhueta
library(cluster)
mls<-numeric(nrow(crabs.20))
mls
for (k in 2:(nrow(crabs.20)-1)){
    sil<-silhouette(cutree(crabs.UPGMA,k=k),crabs.dist)   
    mls[k]<-summary(sil)$avg.width
}
melhor.k<-which.max(mls) #indica qual Ã© o valor mÃ¡ximo
melhor.k

kmeans(crabs.dist,centers=2) #irÃ¡ dividir os dados em K grupos de 2 a 2 porque foi colocado centers=2 # esse teste Ã© usado quando se tem um nÃºmero prÃ©-definido de grupos a serem formados, ou seja vocÃª indica para o programa quantos grupos vocÃª quer que sejam formados
crabs.cascade.KM<-
cascadeKM(crabs.dist,inf.gr=2,sup.gr=19,criterion="ssi")
?cascadeKM
plot(crabs.cascade.KM,sortg=T) #o aior valor de SSI indica a melhor forma de agrupamento
crabs.cascade.KM$results
crabs.cascade.KM$partition

  
23/01/2013

##AnÃ¡lise Multivariada de VariÃ¢ncia (MANOVA)

#Carrega os dados
haynes<-read.table("haynes.dat",h=T)
head(haynes)
attach(haynes)
table(site)

#Examina os dados
pairs(haynes[,2:5],pch=c("D","S","H","W")[as.numeric(site)])
biplot(prcomp(haynes[,2:5]))

#Calcula mÃ©dia das variÃ¡veis
m<-colMeans(haynes[,-1])
m

#Cria matriz de mÃ©dias
mm<-matrix(rep(m,12),12,4,byrow=T)
mm

#Cria matrix com mÃ©dias dos sÃ­tios
delray<-apply(haynes[site=="Delray",-1],2,mean)   #o apply dÃ¡ a mÃ©dia do grupo todo. Faz a mÃ©dia para todo o data.frame
delray

seaspray<-apply(haynes[site=="Seaspray",-1],2,mean) #2 Ã© por coluna
seaspray

woodside<-apply(haynes[site=="Woodside",-1],2,mean)
woodside

mdelray<-matrix(rep(delray,4),4,4,byrow=T)
mdelray

mseaspray<-matrix(rep(seaspray,4),4,4,byrow=T)
mdelray

mwoodside<-matrix(rep(woodside,4),4,4,byrow=T)
mdelray

mg<-rbind(mdelray,mseaspray,mwoodside) #rbind junta as matrizes por linhas
mg

#Cria matriz dos dados originais
mh<-as.matrix(haynes[,-1])
mh

#Cria matriz dos desvios totais
dt<-mh-mm
dt

#Calcula matriz SSCP total
sscp.total<-t(dt)%*%dt #o t Ã© de transposiÃ§Ã£o
sscp.total
round(sscp.total,2)
cov(mh)

#Calcula os desvios das mÃ©dias dos grupos
dg<-mg-mm
dg

#Calcula matriz SScp entre grupos
sscp.grupos<-t(dg)%*%dg
sscp.grupos

#Calcula desvios dentro de grupos
dd<-mh-mg
dd

#Calcula a matriz SSCP dentro de grupos
sscp.dentro<-t(dd)%*%dd
sscp.dentro

#Prova
sscp.total
sscp.grupos+sscp.dentro # esses dois valores tem que ser iguais. Se eles nÃ£od erem iguais, existe alguma coisa errada.

#Calcula lambda de Wilk
det(sscp.dentro)/det(sscp.grupos+sscp.dentro) #quanto menor o valor de lambda de wilk, maior Ã© o valor da diferenÃ§a

#Faz MANOVA
mh<-as.matrix(haynes[,-1])
mh
mhaynes<-manova(mh~site) # mh tem que ser uma matriz. NÃ£o pode ser um data.frame
summary(mhaynes,test="Wilks") #resultado. Existe diferenÃ§a entre os sites com relaÃ§Ã£o aos metais pesados tomados simultaneamente.
print.default(summary(mhaynes))

#VerificaÃ§Ãµes que o Guarino fez
sum(summary(mhaynes)$Eigenvalues)
sum(diag(sscp.grupos))
sum(diag(sscp.dentro))
sum(diag(cov(mh)))
var(lcu)

##AnÃ¡lise Discriminante

library(MASS)
haynes.discr<-lda(site~lcu+lpb+lni+lmn) #lda= linear discriminant analysis #Ã© sempre importante padronizar as medidas dos dados com o scale, mesmo que os dados estejam com as mesmas unidades.
haynes.discr #a quantidade de direÃ§Ãµes de mÃ¡xima variaÃ§Ã£o vai ser sempre igual ao nÃºmero de grupos -1.
             #porporÃ§Ã£o de traÃ§os seria a proporÃ§Ã£o de variaÃ§Ã£o dos grupos que Ã© explicada por cada dimensÃ£o
(haynes.discr<-lda(site~scale(lcu)+scale(lpb)+scale(lni)+scale(lmn)))

#Calcula grupos esperados
(haynes.discr.fit<-predict(haynes.discr)) #dÃ¡ as probabilidades de cada observaÃ§Ã£o a pertencer a esses sÃ­tios. A observaÃ§Ã£o se encaixa naquela que tiver a maior probabilidade.
haynes.discr.fit$class

#Avalia a EficiÃªncia do modelo
table(site,haynes.discr.fit$class) #verifica onde as variÃ¡veis foram classificadas

# GrÃ¡fico das funÃ§Ãµes discriminantes
plot(haynes.discr.fit$x[,1],haynes.discr.fit$x[,2],pch=("D","S","W")[as.numeric(site)])
plot(haynes.discr,dimen=2)

scores<-haynes.discr.fit$x
install.packages("car",dependecies=T)
library(car)
dataEllipse(scores[1:4,1],scores[1:4,2],levels=c(0.95),pch="D",center.pch=19,center.cex=1.5,robust=T,xlim=c(-8,8),ylim=c(-6,6),col="blue",xlab="LDA'",ylab="LDA2",las=1,bty="n")
dataEllipse(scores[5:8,1],scores[5:8,2],levels=c(0.95),pch="D",center.pch=19,center.cex=1.5,robust=T,xlim=c(-8,8),ylim=c(-6,6),col="red",xlab="LDA'",ylab="LDA2",las=1,add=T)
dataEllipse(scores[9:12,1],scores[9:12,2],levels=c(0.95),pch="D",center.pch=19,center.cex=1.5,robust=T,xlim=c(-8,8),ylim=c(-6,6),col="darkgreen",xlab="LDA'",ylab="LDA2",las=1,add=T)

#pode-se olhar tambÃ©m a matriz de confusÃ£o para verificar o quÃ£o bom Ã© o modelo.
#Jacknife 
#Bootstrap

24/01/2013
##AnÃ¡lise de CorrelaÃ§Ã£o CanÃ´nica
#.............

bolger<-read.table("bolgeretal997.txt",h=T)
head(bolger)
pairs(bolger[,-1],col="blue")
biplot(prcomp(bolger[,-1])) #precisa dar o scale pq os dados nÃ£o estÃ£o padronizados
biplot(prcomp(bolger[,-1],scale=T))

install.packages("calibrate",dependencies=T)
library(calibrate)
ccora.bolger<-canocor(bolger[,5:13],bolger[,2:4])
ccora.bolger

$ccor #CorrelaÃ§Ãµes CanÃ´nicas (matriz de correlaÃ§Ã£o canÃ´nica dos dados bolger)
          [,1]      [,2]      [,3]   #esses dados sugerem que a correlaÃ§Ã£o entre esses conjuntos de dados ocorrem em mais de uma dimensÃ£o
[1,] 0.9529602 0.0000000 0.0000000
[2,] 0.0000000 0.7635846 0.0000000
[3,] 0.0000000 0.0000000 0.6248061

$A #Coeficientes canÃ´nicos dos roedores  (sÃ£o 9 linhas pq sÃ£o nove espÃ©cies de roedores e 3 colunas pq sÃ£o 3 variÃ¡veis)
              [,1]        [,2]       [,3]
 [1,] -0.002850132 -0.80107782 -0.6845661
 [2,] -0.002584390  0.09098132 -0.8481207
 [3,]  0.568198932 -0.01610844 -0.6409029
 [4,]  0.640052022 -0.20159616 -1.4474521
 [5,] -1.229873547  0.18930943  1.6412169
 [6,]  1.109863062 -1.16609969 -0.8237638
 [7,]  0.576551311 -0.99234711 -0.6063756
 [8,] -0.076840527 -0.38966869 -0.4752606
 [9,] -0.289454443  1.77032288  1.5435431

$B #Coeficientes canonicos das variÃ¡veis dos fragmentos
           [,1]       [,2]       [,3]
[1,]  0.9414336  0.3784044 -0.1252203
[2,] -0.1670719 -0.1777184 -1.0109448
[3,] -0.1627896  1.0357372  0.1407953

$U #Scores das variÃ¡veis canÃ´nicas dos roedores #tem um score para cada fragmento
             [,1]       [,2]        [,3]
 [1,]  3.46144486  0.9683528 -1.26511715
 [2,]  0.82428660 -0.2552042 -0.40835272
 [3,]  1.88437380  0.8483081  1.03181004
 [4,]  0.50575664 -1.1734271  0.28701547
 [5,]  1.09758644 -0.6455618  1.34274722
 [6,] -0.58980604  1.1140182 -0.83155452
 [7,] -0.59288227  1.2223142 -1.84108106
 [8,] -0.59602820 -1.2185761 -2.16364482
 [9,] -0.58695814  0.1632132  0.33965784
[10,] -0.58857555  1.0706998 -0.42774391
[11,] -0.05205695 -1.8155107  0.33247200
[12,]  0.68641742 -0.5925010  0.03159995
[13,] -0.58757338  0.1848724  0.13775253
[14,] -0.58980604  1.1140182 -0.83155452
[15,] -0.58549933  0.9624038  0.58178263
[16,] -0.59110624 -1.3918497 -0.54840236
[17,] -0.09612707 -1.0631950  1.22836765
[18,] -0.56093285  0.8751404  1.36446986
[19,]  0.04805559 -1.4220977 -1.31731064
[20,] -0.58903219 -0.6143182 -0.10437226
[21,] -0.58488408  0.9407446  0.78368794
[22,] -0.14481077 -0.3758018  1.15442504
[23,] -0.58572765  0.1198948  0.74346846
[24,] -0.58611457  0.9840630  0.37987733

$V #Scores dos fragmentos
             [,1]       [,2]        [,3]
 [1,]  3.23558008  0.5996640 -0.62470123
 [2,]  1.60165088  0.4215704 -1.39551863
 [3,]  1.83075480  0.7253968  0.55259694
 [4,]  0.62371458 -0.6054961 -0.16854644
 [5,]  1.08798213 -0.3997709  0.72845554
 [6,] -0.65531390  1.4328634 -0.72124901
 [7,] -0.49483235  0.6599947 -0.37600595
 [8,] -0.73407704 -0.6084852 -2.71739435
 [9,] -0.21731221 -0.2876025  0.22173028
[10,] -0.43130268  1.4874293  0.86779860
[11,] -0.10199325 -1.0681602  0.28069243
[12,] -0.03636814 -0.6708010  1.00812234
[13,] -0.38252638  0.7558714  0.86328714
[14,] -0.74239186 -0.4988185 -2.05034848
[15,] -0.17769850 -0.5442266  0.79018990
[16,] -0.30923976 -0.7034586  0.20387926
[17,] -0.10127221 -1.1223122  0.94206634
[18,] -0.99187144  1.5617373 -0.93859382
[19,] -0.33932455 -1.4412063 -0.33191617
[20,] -0.35305747 -0.7977037  0.27374755
[21,] -0.65229070  1.5297332  0.95232229
[22,] -0.22949922 -1.4316773  0.89028378
[23,] -0.60271800 -0.4317551 -0.01653333
[24,] -0.82659283  1.4372139  0.76563502

$Fs #CorrelaÃ§Ãµes entre variÃ¡veis canÃ´nicas dos roedores e abundÃ¢ncias das espÃ©cies dos roedores
              [,1]          [,2]        [,3]
rrattus -0.2607352 -5.275054e-01 -0.45438755
mmus    -0.2512870  4.783745e-01 -0.56533023
pcalif   0.7296323 -2.694857e-01  0.19212401
perem    0.7932048  4.349564e-02 -0.08477698
rmegal   0.6741737 -3.364700e-01  0.31011186
nfusc    0.7537739 -2.101649e-01  0.29114924
nlepid   0.6159802  1.206470e-06  0.09032640
pfallax  0.4681222 -2.003904e-02  0.31518707
mcalif   0.8646334  1.972227e-01  0.09416046

$Gs #CorrelaÃ§Ãµes entre as variÃ¡veis canÃ´nicas dos fragmentos e as variÃ¡veis dos fragmentos
            [,1]      [,2]        [,3]
area   0.9654196 0.1776720 -0.19078193
distx -0.1728344 0.1059498 -0.97923589
age   -0.3823700 0.9187633 -0.09832173

$Fp  #CorrelaÃ§Ãµes entre variÃ¡veis canÃ´nicas dos fragmentos e variÃ¡veis dos roedores (abundÃ¢ncia dos roedores nesse caso_
              [,1]          [,2]        [,3]
rrattus -0.2484703 -4.027950e-01 -0.28390412
mmus    -0.2394665  3.652794e-01 -0.35322179
pcalif   0.6953105 -2.057751e-01  0.12004026
perem    0.7558926  3.321260e-02 -0.05296918
rmegal   0.6424607 -2.569233e-01  0.19375979
nfusc    0.7183165 -1.604787e-01  0.18191183
nlepid   0.5870045  9.212415e-07  0.05643649
pfallax  0.4461018 -1.530150e-02  0.19693081
mcalif   0.8239612  1.505962e-01  0.05883203

$Gp #CorrelaÃ§Ãµes entre variÃ¡veis canÃ´nicas dos roedores e variÃ¡veis dos fragmentos
            [,1]       [,2]        [,3]
area   0.9200064 0.13566758 -0.11920172
distx -0.1647043 0.08090161 -0.61183258
age   -0.3643833 0.70155352 -0.06143202

$fitRxy #Autovalores da matriz de correlaÃ§Ã£o canÃ´nica
          [,1]      [,2]      [,3]
lamb 0.9081331 0.5830614 0.3903827
frac 0.4826446 0.3098791 0.2074763
cumu 0.4826446 0.7925237 1.0000000

$fitXs #ProporÃ§Ã£o da variaÃ§Ã£o dos roedores explicada por suas variÃ¡veis canÃ´nicas
           [,1]       [,2]       [,3]
AdeX  0.4068346 0.08647758 0.09638558
cAdeX 0.4068346 0.49331218 0.58969776

$fitXp #ProporÃ§Ã£o da variaÃ§Ã£o dos parÃ¢metros dos roedores explicados pos suas variÃ¡veis can}onicas
           [,1]       [,2]       [,3]
RedX  0.3694599 0.05042174 0.03762726
cRedX 0.3694599 0.41988169 0.45750896

$fitYs #ProporÃ§Ã£o da variaÃ§Ã£o dos fragmentos explicada pelas suas variÃ¡veis canÃ´nicas  # Essa soma dÃ¡ um porque foram geradas 3 variÃ¡veis canÃ´nicas,e sÃ£o 3 variÃ¡veis medidas (Ã¡rea, idade e distÃ¢ncia)
           [,1]      [,2]      [,3]
AdeY  0.3693711 0.2956396 0.3349893
cAdeY 0.3693711 0.6650107 1.0000000

$fitYp #ProporÃ§Ã£o da variaÃ§Ã£o dos fragmentos explicada pelas variÃ¡veis canÃ´nnicas dos roedores
           [,1]      [,2]      [,3]
RedY  0.3354382 0.1723760 0.1307740
cRedY 0.3354382 0.5078142 0.6385882

cor(ccora.bolger$U[,1],ccora.bolger$V[,1])
plot(cor(ccora.bolger$U[,1],ccora.bolger$V[,1]))
 
##AnÃ¡lise de redundÃ¢ncia
#...............

install.packages("vegan",dependencies=T)
library(vegan)
especies<-bolger[,5:13]
ambientes<-bolger[,2:4]

bolger.rda<-rda(especies~area+distx+age,ambientes) #diz a proporÃ§Ã£o da variaÃ§Ã£o explicada
summary(bolger.rda)

sum(diag(cov(especies)))

Call:
rda(formula = especies ~ area + distx + age, data = ambientes) 

Partitioning of variance: #dÃ¡ a variÃ¢ncia explicada e nÃ£o explicada pelo modelo
              Inertia Proportion
Total          1015.0     1.0000
Constrained     547.9     0.5399
Unconstrained   467.0     0.4601

Eigenvalues, and their contribution to the variance 

Importance of components:
                          RDA1     RDA2    RDA3      PC1      PC2     PC3
Eigenvalue            527.0849 19.72285 1.13755 314.4636 111.6700 22.3245
Proportion Explained    0.5193  0.01943 0.00112   0.3098   0.1100  0.0220
Cumulative Proportion   0.5193  0.53874 0.53986   0.8497   0.9597  0.9817
                           PC4     PC5     PC6     PC7     PC8     PC9
Eigenvalue            11.71459 3.66700 2.39675 0.43059 0.35389 0.01212
Proportion Explained   0.01154 0.00361 0.00236 0.00042 0.00035 0.00001
Cumulative Proportion  0.99324 0.99685 0.99922 0.99964 0.99999 1.00000

Accumulated constrained eigenvalues #Da variaÃ§Ã£o explicada pelo modelo, o primeiro componente explicou  ~96% da variaÃ§Ã£o
Importance of components:
                          RDA1     RDA2    RDA3
Eigenvalue            527.0849 19.72285 1.13755
Proportion Explained    0.9619  0.03599 0.00208
Cumulative Proportion   0.9619  0.99792 1.00000

Scaling 2 for species and site scores
* Species are scaled proportional to eigenvalues
* Sites are unscaled: weighted dispersion equal on all dimensions
* General scaling constant of scores:  12.36079 


Species scores #As RDA1 e RDA2 seriam as coordenadas de onde as setas de cada uma das espÃ©cies e ambientes ficariam no grÃ¡fico

            RDA1     RDA2     RDA3       PC1      PC2      PC3
rrattus  0.07988 -0.07880  0.19725 -0.080380  0.01562 -0.11629
mmus     0.57056  0.70957  0.09537  0.037338 -0.23580  0.22904
pcalif  -7.29980 -0.65314  0.11829  6.755613  0.05786 -0.28983
perem   -4.23198  1.38025 -0.01228  0.126485  3.78060  0.54527
rmegal  -1.08938 -0.25134 -0.01981  0.803901  0.41885  0.39708
nfusc   -2.37688 -0.19987 -0.20664  1.002511 -1.05480  1.41736
nlepid  -0.64587  0.11616 -0.06966 -0.014479  0.69413  0.06516
pfallax -0.69705 -0.03979 -0.24025  0.154618 -0.82892  0.85514
mcalif  -0.27641  0.09688 -0.05854 -0.002588  0.03280  0.10576


Site scores (weighted sums of species scores)

         RDA1     RDA2     RDA3      PC1      PC2     PC3
row1  -7.3942  17.4030   3.0263 -1.89682  5.63820  0.5606
row2  -1.5748  -6.7985  11.1934 -0.60556 -5.43257 -6.4236
row3  -4.0310 -11.8844 -29.1030  1.04486 -7.35372  4.5220
row4  -5.5266  -4.6866  17.7369  4.88298  1.92188  1.4263
row5  -4.7967   5.8446   6.9814  1.08020  5.07918  0.4559
row6   2.0847   3.5694   1.3153  0.73149  0.15569  0.8167
row7   2.1206   4.7643   4.0999 -0.48965 -0.09848  0.4231
row8   2.0661   2.7727   3.1002  0.28134  0.14796  1.5899
row9   2.0209   1.3918  -2.5452 -2.31132 -0.27071 -1.8256
row10  2.0703   3.0914   0.2014 -0.61338  0.05766 -0.7905
row11  1.3257  -0.1568 -32.1567 -2.68765 -1.65719  6.8587
row12 -1.9681  -7.8297   9.4141  2.39511 -0.99014 -0.4702
row13  2.0281   1.6308  -1.9883 -1.33492  0.12480 -1.4233
row14  2.0847   3.5694   1.3153  0.07587  0.27713  1.6437
row15  2.0343   1.8964  -2.5833 -2.89708 -0.21384 -2.0454
row16  2.0086   0.8608  -1.3553 -2.38593  0.02389 -1.7105
row17 -5.7480 -17.5835  26.5216  7.96750 -0.80686 -1.1546
row18  1.9136   0.7204  -4.1202  2.00025  1.02537  1.2636
row19 -0.5288  -4.6141  17.2245  1.22448  0.37357 -3.5600
row20  2.0148   1.1263  -1.9503 -2.37175  0.14122 -1.4858
row21  2.0271   1.6574  -3.1402 -0.01687  0.67253 -0.4559
row22  1.7209   0.2057 -17.5023 -3.30341 -0.44497  1.9174
row23  2.0066   0.9138  -3.6591 -1.25112  0.61392 -0.5051
row24  2.0415   2.1354  -2.0263  0.48138  1.01546  0.3725


Site constraints (linear combinations of constraining variables)

          RDA1    RDA2     RDA3      PC1      PC2     PC3
row1  -7.59028  4.1124  0.05230 -1.89682  5.63820  0.5606
row2  -3.34935  3.9802  2.02453 -0.60556 -5.43257 -6.4236
row3  -4.37828  1.6635 -2.41924  1.04486 -7.35372  4.5220
row4  -1.82565 -0.5421  1.25760  4.88298  1.92188  1.4263
row5  -3.16326 -1.2626 -0.92179  1.08020  5.07918  0.4559
row6   2.61873  3.5340 -0.77470  0.73149  0.15569  0.8167
row7   1.70324  1.5794 -0.25304 -0.48965 -0.09848  0.4231
row8   2.37637  2.6191  6.52579  0.28134  0.14796  1.5899
row9   0.32355 -1.0413  0.02729 -2.31132 -0.27071 -1.8256
row10  1.58525  1.2888 -4.09409 -0.61338  0.05766 -0.7905
row11 -0.39260 -2.5902  1.14394 -2.68765 -1.65719  6.8587
row12 -0.57822 -2.9121 -0.96665  2.39511 -0.99014 -0.4702
row13  1.08139 -0.1052 -2.92195 -1.33492  0.12480 -1.4233
row14  2.24424  1.7843  5.00207  0.07587  0.27713  1.6437
row15 -0.08933 -2.4091 -0.71652 -2.89708 -0.21384 -2.0454
row16  0.34155 -1.8824  0.73396 -2.38593  0.02389 -1.7105
row17 -0.63136 -3.7311 -0.10773  7.96750 -0.80686 -1.1546
row18  3.59747  3.9223 -0.51404  2.00025  1.02537  1.2636
row19  0.19947 -2.5046  2.99699  1.22448  0.37357 -3.5600
row20  0.37987 -2.2026  0.74639 -2.37175  0.14122 -1.4858
row21  2.13407  1.1053 -4.31514 -0.01687  0.67253 -0.4559
row22 -0.45599 -4.3328  0.50058 -3.30341 -0.44497  1.9174
row23  1.28820 -1.1839  0.76961 -1.25112  0.61392 -0.5051
row24  2.58091  1.1109 -3.77616  0.48138  1.01546  0.3725


Biplot scores for constraining variables

         RDA1   RDA2     RDA3 PC1 PC2 PC3
area  -0.8784 0.4778  0.01027   0   0   0
distx  0.3093 0.6345  0.70833   0   0   0
age    0.5702 0.6669 -0.47971   0   0   0

> 
coef(bolger.rda)
plot(bolger.rda)
plot(bolger.rda,scaling=1)
anova.cca(bolger.rda,step=1000) #teste de significÃ¢ncia do modelo com aleatorizaÃ§Ã£o (a aleatorizaÃ§Ã£o Ã© necessÃ¡ria)
anova.cca(bolger.rda,by="axis",step=1000)
anova.cca(bolger.rda,by="terms",step=1000)
m.nula<-rda(especies~1,ambientes)
m.complete<-rda(especies~area+distx+age,ambientes)
add1(m.nula,scope=m.complete,test="perm",pstep=1000)
m.nula<-update(m.nula,.~.+area)
add1(m.nula,scope=m.complete,test="perm",pstep=1000)
m.nula<-update(m.nula,.~.+age)
add1(m.nula,scope=m.complete,test="perm",pstep=1000)

ordistep(m.nula,scope=formula(m.complete),direction="forward",pstep=1000)
ordistep(m.nula,scope=formula(m.complete),direction="both",pstep=1000)

25/01/2013

#Aula 14 - AnÃ¡lise de CorrespondÃªncia CanÃ´nica (CCA)

bolger<-read.table("Bolgeretal1997.txt",h=T)
head(bolger)
str(bolger)

# Examina os dados
pairs(bolger[,2:13],pch=1,col="blue")
biplot(prcomp(bolger[,2:13])) #efeito da escala das variaveis
biplot(prcomp(bolger[,2:13],scale=T))


## Analise de Correspondencia Canonica
#  **********************
install.packages("vegan",dependencies=T)
library(vegan)
especies<-bolger[,5:13]
ambiente<-bolger[,2:4]

bolger.cca<-cca(especies~area+distx+age,ambiente)
bolger.cca
summary(bolger.cca)

sum(diag(cov(species)))

# Coeficientes canonicos para cada X
coef(bolger.cca)

# Faz grafico
plot(bolger.cca)
plot(bolger.cca,scaling=1)

# Teste da significancia global da cca
anova.cca(bolger.cca,step=1000)

# Teste da significancia dos eixos da cca
anova.cca(bolger.cca,by="axis",step=1000)

# Teste da significancia dos Xs da cca
anova.cca(bolger.cca,by="terms",step=1000)

# Variance inflation factors (colinearidade)
#proporcao da variancia de um coeficiente de regressao que e inflada na presenca de 
outras variaveis independentes
vif.cca(bolger.cca)

# Selecao de modelos
m.nulo<-cca(especies~1,ambiente)
m.completo<-cca(especies~area+distx+age,ambiente)
add1(m.nulo,scope=m.completo,test="perm",pstep=1000)
m.nulo<-update(m.nulo,.~.+area)
add1(m.nulo,scope=m.completo,test="perm",pstep=1000)
m.nulo<-update(m.nulo,.~.+age)
drop1(m.nulo,test="perm",pstep=1000)
add1(m.nulo,scope=m.completo,test="perm",pstep=1000)
m.nulo<-cca(especies~1,ambiente)
ordistep(m.nulo,scope=formula(m.completo),direction="forward",pstep=1000)
ordistep(m.nulo,scope=formula(m.completo),direction="both",pstep=1000)

ordirgl(bolger.cca,type="t",scaling=1)
orglspider(bolger.cca,scaling=1,color="cyan")
ordirgl(bolger.cca,type="t",scaling=1)
orgltext(bolger.cca,display="species",type="t",scaling=2,col="purple")

#Hotelling test (Teste t mulivariado)
## Carregar pacote Hotelling
fit<-hotelling.test(cc+ecto~preservacao, data = slil, perm = T,B = 10000) #Hotelling com permutaÃ§Ãµes #data=aos dados que eu estou testando
 
